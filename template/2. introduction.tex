\section{Introduction}
Learning similarities have gained more popularity in deep learning, especially in face verification and face identification tasks. Instead of predicting a probability distribution to find the label that fits best for the input image, the algorithm compares the distance between the input image with all the remaining images. Since this method doesn't depend on the number of labels, there is no need to re-train when new labels appear and still find similar images. The main point is to build a good DCNN model to project the images onto an n-dimensional Euclidean space, the distance will be used to decide the labels afterward.
There are two main ways to train the DCNNs more effectively: train a classification-based model by using Softmax loss \cite{liu2017sphereface, wang2018support, wang2018cosface, deng2019arcface, zhang2019adacos, boutros2022elasticface} or optimize the distance directly from the vector embeddings during training \cite{dubey2018pairwise}, \cite{schroff2015facenet}. Although both methods have shown decent results, they still have some shortcomings. Since triplet loss compares three samples at a time, with the increase in the amount of data, the number of triplets will also increase exponentially resulting in a significant increase in the number of iterations. The method that is said to be optimal when training with triplet loss is semi-hard sample training, which is quite difficult to train effectively. On the other hand, there are several variants of Softmax loss have been proposed and proven to carry some different drawbacks. For instance, the traditional Softmax loss has its boundary dependent on both the magnitude of weights and the angles, therefore the boundary overlaps on the decision area in cosine space; Normalized Version of Softmax Loss (NSL) performs weaker with noise; A-Softmax \cite{liu2017sphereface} loss reduces its boundary when the angles decrease and may completely vanish when the angles come to zero. Some improved versions of Softmax loss have been proposed, such as CosFace, ArcFacem, and ElasticFace. However, they all shared a common of applying cosine loss to calculate the angles between the feature vectors and corresponding weights.

In this work, we propose Large Margin Cotangent Loss by building it on top of ArcFace. We explain the advancement of cotangent compared to cosine, followed by some detailed pseudo code implementations. We also suggest the ensemble technique with the existing loss functions to increase performance. Afterward, several experiments are explicitly clarified, and a specific comparative discussion of the achieved results with those obtained from other losses on many datasets and competitions. The advantages of the proposed LMCot can be summarized as follows:

\noindent \textbf{Engaging.} LMCot optimizes the angle of weights and feature vectors by using cotangent instead of cosine. The cosine value is limited on range $\left[ -1 ,+1  \right]$, whereas the cotangent value is unlimited on range $\left( -\infty ,+\infty  \right)$.  This helps the cotangent perform better than the cosine when the angle is too small or too large.\\
\textbf{Effective.} LMCot achieves state-of-the-art on all benchmarks that we tested. Using the same backbone, the model trained by LMCot has better results than the model trained by ArcFace.\\
\textbf{Efficient.} We propose two pseudo code versions of LMCot. Among these two versions, we provide a solution that skips the arc-cosine calculating steps to improve the computation efficiency.